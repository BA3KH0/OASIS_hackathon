{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, ConcatDataset\nfrom torchvision import datasets\nfrom torch.utils.data import Subset\nfrom sklearn.model_selection import train_test_split\nimport torchvision.models as models\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torch.utils.data import random_split\nfrom torch.utils.data import Subset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-26T04:16:21.106925Z","iopub.execute_input":"2023-08-26T04:16:21.107330Z","iopub.status.idle":"2023-08-26T04:16:21.115329Z","shell.execute_reply.started":"2023-08-26T04:16:21.107290Z","shell.execute_reply":"2023-08-26T04:16:21.114245Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport time\nimport os\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-08-26T02:55:16.332448Z","iopub.execute_input":"2023-08-26T02:55:16.333316Z","iopub.status.idle":"2023-08-26T02:55:16.338792Z","shell.execute_reply.started":"2023-08-26T02:55:16.333267Z","shell.execute_reply":"2023-08-26T02:55:16.337490Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(f'Using {device} for inference')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T02:55:17.425932Z","iopub.execute_input":"2023-08-26T02:55:17.426950Z","iopub.status.idle":"2023-08-26T02:55:17.460524Z","shell.execute_reply.started":"2023-08-26T02:55:17.426901Z","shell.execute_reply":"2023-08-26T02:55:17.459399Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Using cuda for inference\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport torchvision.transforms as transforms\n\nclass CustomDataset(Dataset):\n    def __init__(self, root_dir, class_name, transform=None, limit=None):\n        self.root_dir = root_dir\n        self.class_name = class_name\n        self.transform = transform\n        self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir)][:limit]\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path)\n        if self.transform:\n            image = self.transform(image)\n        return image, self.class_name\n\n# 데이터셋 경로\ndataset_path = '/kaggle/input/wall-classification'\n\n# 데이터 변환 설정\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(300),\n        transforms.RandomResizedCrop(256),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize(300),\n        transforms.CenterCrop(256),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n}\n\n# 'bad' 폴더에서 1500장 이미지 가져오기\nbad_dataset = CustomDataset(os.path.join(dataset_path, 'bad'), class_name=0, transform=data_transforms['train'], limit=1500)\n\n# 'good', 'normal' 폴더에서 전체 이미지 가져오기\ngood_dataset = CustomDataset(os.path.join(dataset_path, 'good'), class_name=1, transform=data_transforms['train'])\nnormal_dataset = CustomDataset(os.path.join(dataset_path, 'normal'), class_name=2, transform=data_transforms['train'])\n\n# 생성한 데이터셋 합치기\ncombined_dataset = Subset(bad_dataset, list(range(len(bad_dataset)))) + good_dataset + normal_dataset\n\n# 데이터 로더 설정\nbatch_size = 32\ntrain_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n\n# 데이터셋 정보 출력\nprint(\"Number of images in combined_dataset:\", len(combined_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T04:46:25.923889Z","iopub.execute_input":"2023-08-26T04:46:25.924287Z","iopub.status.idle":"2023-08-26T04:46:25.965713Z","shell.execute_reply.started":"2023-08-26T04:46:25.924255Z","shell.execute_reply":"2023-08-26T04:46:25.964611Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Number of images in combined_dataset: 2869\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 데이터셋을 train과 valid로 나누기 (8:2 비율)\ndataset_size = len(combined_dataset)\ntrain_size = int(0.8 * dataset_size)  # 전체 데이터셋 중 80%를 훈련 데이터로 사용\n\ntrain_dataset, valid_dataset = train_test_split(combined_dataset, test_size=0.2, random_state=42)\n\n# 데이터 로더 설정\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T04:46:27.788733Z","iopub.execute_input":"2023-08-26T04:46:27.789090Z","iopub.status.idle":"2023-08-26T04:48:03.395322Z","shell.execute_reply.started":"2023-08-26T04:46:27.789060Z","shell.execute_reply":"2023-08-26T04:48:03.394244Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"model = models.resnet50(pretrained=False)\nnum_features = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_features, 3)\n\n\n# GPU 사용 가능하면 GPU로 전환\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n\n# 손실 함수와 옵티마이저 정의\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5)\n\n\nbest_val_loss = float('inf')  # 초기값으로 무한대 설정\nbest_model_dir = '/kaggle/working'  # 모델을 저장할 경로\n\n\n\ntrain_losses = []\nvalid_losses = []\nvalid_accuracies = []\n\n\n\n# 모델 학습\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    start_time = time.time()  # 에포크 시작 시간\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        \n    avg_train_loss = running_loss / len(train_loader)\n    train_losses.append(avg_train_loss)  # 훈련 손실 리스트에 추가\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(train_loader):.4f}')\n\n    \n    \n    # Validation 성능 평가\n    model.eval()\n    valid_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in valid_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            valid_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            \n    avg_valid_loss = valid_loss / len(valid_loader)\n    valid_losses.append(avg_valid_loss)  # 검증 손실 리스트에 추가\n    valid_accuracy = 100 * correct / total\n    valid_accuracies.append(valid_accuracy)  # 검증 정확도 리스트에 추가\n\n            \n        \n    end_time = time.time()  # 에포크 종료 시간\n    epoch_time = end_time - start_time  # 에포크 소요 시간\n\n    scheduler.step(avg_valid_loss)  # 학습률 스케줄러 업데이트\n    \n    \n    if valid_loss < best_val_loss:\n        if epoch > 5:\n            best_val_loss = valid_loss\n            best_model_path = os.path.join(best_model_dir, f'normal_classification_{epoch+1}epoch.pth')\n            torch.save(model.state_dict(), best_model_path)\n            print(f'Saved best model with validation loss: {valid_loss/len(valid_loader):.4f} at epoch {epoch+1}')\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n          f\"Validation Loss: {valid_loss/len(valid_loader):.4f}, \"\n          f\"Validation Accuracy: {(100 * correct / total):.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-08-26T04:58:38.795071Z","iopub.execute_input":"2023-08-26T04:58:38.795495Z","iopub.status.idle":"2023-08-26T05:26:03.385832Z","shell.execute_reply.started":"2023-08-26T04:58:38.795461Z","shell.execute_reply":"2023-08-26T05:26:03.384553Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Epoch [1/100], Training Loss: 1.0103\nEpoch [1/100] - Validation Loss: 0.8806, Validation Accuracy: 61.67%\nEpoch [2/100], Training Loss: 0.8898\nEpoch [2/100] - Validation Loss: 0.9902, Validation Accuracy: 54.36%\nEpoch [3/100], Training Loss: 0.8279\nEpoch [3/100] - Validation Loss: 0.7640, Validation Accuracy: 64.63%\nEpoch [4/100], Training Loss: 0.7806\nEpoch [4/100] - Validation Loss: 0.7689, Validation Accuracy: 65.16%\nEpoch [5/100], Training Loss: 0.7568\nEpoch [5/100] - Validation Loss: 1.3253, Validation Accuracy: 48.43%\nEpoch [6/100], Training Loss: 0.6680\nEpoch [6/100] - Validation Loss: 1.3487, Validation Accuracy: 55.57%\nEpoch [7/100], Training Loss: 0.6570\nSaved best model with validation loss: 12.239794611930847 at epoch 7\nEpoch [7/100] - Validation Loss: 0.6800, Validation Accuracy: 67.77%\nEpoch [8/100], Training Loss: 0.5965\nEpoch [8/100] - Validation Loss: 1.2457, Validation Accuracy: 58.54%\nEpoch [9/100], Training Loss: 0.5556\nSaved best model with validation loss: 11.887664586305618 at epoch 9\nEpoch [9/100] - Validation Loss: 0.6604, Validation Accuracy: 72.65%\nEpoch [10/100], Training Loss: 0.4704\nSaved best model with validation loss: 11.342986196279526 at epoch 10\nEpoch [10/100] - Validation Loss: 0.6302, Validation Accuracy: 74.56%\nEpoch [11/100], Training Loss: 0.4681\nEpoch [11/100] - Validation Loss: 0.6410, Validation Accuracy: 75.26%\nEpoch [12/100], Training Loss: 0.4363\nEpoch [12/100] - Validation Loss: 1.1287, Validation Accuracy: 68.12%\nEpoch [13/100], Training Loss: 0.3944\nEpoch [13/100] - Validation Loss: 0.8313, Validation Accuracy: 67.94%\nEpoch [14/100], Training Loss: 0.3739\nEpoch [14/100] - Validation Loss: 0.7599, Validation Accuracy: 72.13%\nEpoch [15/100], Training Loss: 0.3080\nEpoch [15/100] - Validation Loss: 0.8078, Validation Accuracy: 74.22%\nEpoch [16/100], Training Loss: 0.2767\nEpoch [16/100] - Validation Loss: 0.7987, Validation Accuracy: 72.13%\nEpoch [17/100], Training Loss: 0.1824\nSaved best model with validation loss: 9.109017357230186 at epoch 17\nEpoch [17/100] - Validation Loss: 0.5061, Validation Accuracy: 80.31%\nEpoch [18/100], Training Loss: 0.1379\nEpoch [18/100] - Validation Loss: 0.5203, Validation Accuracy: 79.97%\nEpoch [19/100], Training Loss: 0.1143\nSaved best model with validation loss: 9.051195606589317 at epoch 19\nEpoch [19/100] - Validation Loss: 0.5028, Validation Accuracy: 81.71%\nEpoch [20/100], Training Loss: 0.0996\nEpoch [20/100] - Validation Loss: 0.5072, Validation Accuracy: 81.01%\nEpoch [21/100], Training Loss: 0.0822\nEpoch [21/100] - Validation Loss: 0.5267, Validation Accuracy: 81.71%\nEpoch [22/100], Training Loss: 0.0803\nEpoch [22/100] - Validation Loss: 0.5295, Validation Accuracy: 81.88%\nEpoch [23/100], Training Loss: 0.0860\nEpoch [23/100] - Validation Loss: 0.5388, Validation Accuracy: 81.88%\nEpoch [24/100], Training Loss: 0.0750\nEpoch [24/100] - Validation Loss: 0.5086, Validation Accuracy: 82.93%\nEpoch [25/100], Training Loss: 0.0643\nEpoch [25/100] - Validation Loss: 0.5348, Validation Accuracy: 81.53%\nEpoch [26/100], Training Loss: 0.0596\nEpoch [26/100] - Validation Loss: 0.5343, Validation Accuracy: 82.06%\nEpoch [27/100], Training Loss: 0.0603\nEpoch [27/100] - Validation Loss: 0.5231, Validation Accuracy: 81.36%\nEpoch [28/100], Training Loss: 0.0577\nEpoch [28/100] - Validation Loss: 0.5414, Validation Accuracy: 80.84%\nEpoch [29/100], Training Loss: 0.0543\nEpoch [29/100] - Validation Loss: 0.5149, Validation Accuracy: 81.71%\nEpoch [30/100], Training Loss: 0.0536\nEpoch [30/100] - Validation Loss: 0.5290, Validation Accuracy: 83.45%\nEpoch [31/100], Training Loss: 0.0531\nEpoch [31/100] - Validation Loss: 0.5219, Validation Accuracy: 82.40%\nEpoch [32/100], Training Loss: 0.0441\nEpoch [32/100] - Validation Loss: 0.5246, Validation Accuracy: 83.45%\nEpoch [33/100], Training Loss: 0.0552\nEpoch [33/100] - Validation Loss: 0.5135, Validation Accuracy: 82.93%\nEpoch [34/100], Training Loss: 0.0494\nEpoch [34/100] - Validation Loss: 0.5070, Validation Accuracy: 82.75%\nEpoch [35/100], Training Loss: 0.0557\nEpoch [35/100] - Validation Loss: 0.5104, Validation Accuracy: 82.06%\nEpoch [36/100], Training Loss: 0.0575\nEpoch [36/100] - Validation Loss: 0.5090, Validation Accuracy: 81.88%\nEpoch [37/100], Training Loss: 0.0535\nEpoch [37/100] - Validation Loss: 0.5265, Validation Accuracy: 82.40%\nEpoch [38/100], Training Loss: 0.0519\nEpoch [38/100] - Validation Loss: 0.5166, Validation Accuracy: 82.93%\nEpoch [39/100], Training Loss: 0.0573\nEpoch [39/100] - Validation Loss: 0.5289, Validation Accuracy: 82.75%\nEpoch [40/100], Training Loss: 0.0507\nEpoch [40/100] - Validation Loss: 0.5202, Validation Accuracy: 83.10%\nEpoch [41/100], Training Loss: 0.0533\nEpoch [41/100] - Validation Loss: 0.5200, Validation Accuracy: 82.06%\nEpoch [42/100], Training Loss: 0.0579\nEpoch [42/100] - Validation Loss: 0.5243, Validation Accuracy: 83.10%\nEpoch [43/100], Training Loss: 0.0456\nEpoch [43/100] - Validation Loss: 0.5102, Validation Accuracy: 82.75%\nEpoch [44/100], Training Loss: 0.0493\nEpoch [44/100] - Validation Loss: 0.5092, Validation Accuracy: 82.75%\nEpoch [45/100], Training Loss: 0.0517\nSaved best model with validation loss: 9.035347148776054 at epoch 45\nEpoch [45/100] - Validation Loss: 0.5020, Validation Accuracy: 83.10%\nEpoch [46/100], Training Loss: 0.0516\nEpoch [46/100] - Validation Loss: 0.5112, Validation Accuracy: 83.28%\nEpoch [47/100], Training Loss: 0.0685\nEpoch [47/100] - Validation Loss: 0.5181, Validation Accuracy: 82.58%\nEpoch [48/100], Training Loss: 0.0524\nEpoch [48/100] - Validation Loss: 0.5275, Validation Accuracy: 82.40%\nEpoch [49/100], Training Loss: 0.0460\nEpoch [49/100] - Validation Loss: 0.5127, Validation Accuracy: 82.93%\nEpoch [50/100], Training Loss: 0.0506\nEpoch [50/100] - Validation Loss: 0.5146, Validation Accuracy: 82.75%\nEpoch [51/100], Training Loss: 0.0498\nEpoch [51/100] - Validation Loss: 0.5337, Validation Accuracy: 81.88%\nEpoch [52/100], Training Loss: 0.0629\nEpoch [52/100] - Validation Loss: 0.5244, Validation Accuracy: 83.28%\nEpoch [53/100], Training Loss: 0.0510\nEpoch [53/100] - Validation Loss: 0.5091, Validation Accuracy: 82.40%\nEpoch [54/100], Training Loss: 0.0452\nEpoch [54/100] - Validation Loss: 0.5466, Validation Accuracy: 81.53%\nEpoch [55/100], Training Loss: 0.0519\nEpoch [55/100] - Validation Loss: 0.5388, Validation Accuracy: 82.40%\nEpoch [56/100], Training Loss: 0.0600\nEpoch [56/100] - Validation Loss: 0.5209, Validation Accuracy: 82.06%\nEpoch [57/100], Training Loss: 0.0630\nEpoch [57/100] - Validation Loss: 0.5330, Validation Accuracy: 81.36%\nEpoch [58/100], Training Loss: 0.0579\nEpoch [58/100] - Validation Loss: 0.5198, Validation Accuracy: 82.58%\nEpoch [59/100], Training Loss: 0.0514\nEpoch [59/100] - Validation Loss: 0.5247, Validation Accuracy: 82.93%\nEpoch [60/100], Training Loss: 0.0523\nEpoch [60/100] - Validation Loss: 0.5353, Validation Accuracy: 82.40%\nEpoch [61/100], Training Loss: 0.0612\nEpoch [61/100] - Validation Loss: 0.5127, Validation Accuracy: 82.23%\nEpoch [62/100], Training Loss: 0.0493\nEpoch [62/100] - Validation Loss: 0.5229, Validation Accuracy: 82.06%\nEpoch [63/100], Training Loss: 0.0527\nEpoch [63/100] - Validation Loss: 0.5070, Validation Accuracy: 82.06%\nEpoch [64/100], Training Loss: 0.0469\nSaved best model with validation loss: 9.019003689289093 at epoch 64\nEpoch [64/100] - Validation Loss: 0.5011, Validation Accuracy: 83.45%\nEpoch [65/100], Training Loss: 0.0444\nEpoch [65/100] - Validation Loss: 0.5176, Validation Accuracy: 83.62%\nEpoch [66/100], Training Loss: 0.0501\nEpoch [66/100] - Validation Loss: 0.5466, Validation Accuracy: 82.06%\nEpoch [67/100], Training Loss: 0.0530\nEpoch [67/100] - Validation Loss: 0.5234, Validation Accuracy: 82.23%\nEpoch [68/100], Training Loss: 0.0533\nEpoch [68/100] - Validation Loss: 0.5322, Validation Accuracy: 82.75%\nEpoch [69/100], Training Loss: 0.0539\nEpoch [69/100] - Validation Loss: 0.5178, Validation Accuracy: 82.23%\nEpoch [70/100], Training Loss: 0.0562\nEpoch [70/100] - Validation Loss: 0.5344, Validation Accuracy: 82.93%\nEpoch [71/100], Training Loss: 0.0768\nEpoch [71/100] - Validation Loss: 0.5166, Validation Accuracy: 82.06%\nEpoch [72/100], Training Loss: 0.0519\nEpoch [72/100] - Validation Loss: 0.5357, Validation Accuracy: 83.10%\nEpoch [73/100], Training Loss: 0.0526\nEpoch [73/100] - Validation Loss: 0.5408, Validation Accuracy: 83.10%\nEpoch [74/100], Training Loss: 0.0506\nEpoch [74/100] - Validation Loss: 0.5269, Validation Accuracy: 81.88%\nEpoch [75/100], Training Loss: 0.0501\nEpoch [75/100] - Validation Loss: 0.5187, Validation Accuracy: 83.45%\nEpoch [76/100], Training Loss: 0.0603\nEpoch [76/100] - Validation Loss: 0.5226, Validation Accuracy: 82.40%\nEpoch [77/100], Training Loss: 0.0599\nEpoch [77/100] - Validation Loss: 0.5358, Validation Accuracy: 82.58%\nEpoch [78/100], Training Loss: 0.0587\nEpoch [78/100] - Validation Loss: 0.5256, Validation Accuracy: 82.40%\nEpoch [79/100], Training Loss: 0.0585\nEpoch [79/100] - Validation Loss: 0.5440, Validation Accuracy: 81.71%\nEpoch [80/100], Training Loss: 0.0658\nEpoch [80/100] - Validation Loss: 0.5265, Validation Accuracy: 82.58%\nEpoch [81/100], Training Loss: 0.0583\nEpoch [81/100] - Validation Loss: 0.5258, Validation Accuracy: 82.58%\nEpoch [82/100], Training Loss: 0.0537\nEpoch [82/100] - Validation Loss: 0.5356, Validation Accuracy: 82.93%\nEpoch [83/100], Training Loss: 0.0547\nEpoch [83/100] - Validation Loss: 0.5191, Validation Accuracy: 82.23%\nEpoch [84/100], Training Loss: 0.0552\nEpoch [84/100] - Validation Loss: 0.5192, Validation Accuracy: 82.06%\nEpoch [85/100], Training Loss: 0.0499\nEpoch [85/100] - Validation Loss: 0.5340, Validation Accuracy: 82.40%\nEpoch [86/100], Training Loss: 0.0695\nEpoch [86/100] - Validation Loss: 0.5094, Validation Accuracy: 81.71%\nEpoch [87/100], Training Loss: 0.0499\nEpoch [87/100] - Validation Loss: 0.5421, Validation Accuracy: 81.71%\nEpoch [88/100], Training Loss: 0.0553\nEpoch [88/100] - Validation Loss: 0.5315, Validation Accuracy: 83.28%\nEpoch [89/100], Training Loss: 0.0482\nEpoch [89/100] - Validation Loss: 0.5357, Validation Accuracy: 83.10%\nEpoch [90/100], Training Loss: 0.0568\nEpoch [90/100] - Validation Loss: 0.5078, Validation Accuracy: 82.58%\nEpoch [91/100], Training Loss: 0.0472\nEpoch [91/100] - Validation Loss: 0.5194, Validation Accuracy: 83.45%\nEpoch [92/100], Training Loss: 0.0526\nEpoch [92/100] - Validation Loss: 0.5106, Validation Accuracy: 82.75%\nEpoch [93/100], Training Loss: 0.0487\nEpoch [93/100] - Validation Loss: 0.5209, Validation Accuracy: 83.45%\nEpoch [94/100], Training Loss: 0.0588\nEpoch [94/100] - Validation Loss: 0.5112, Validation Accuracy: 82.40%\nEpoch [95/100], Training Loss: 0.0575\nEpoch [95/100] - Validation Loss: 0.5381, Validation Accuracy: 82.23%\nEpoch [96/100], Training Loss: 0.0527\nEpoch [96/100] - Validation Loss: 0.5579, Validation Accuracy: 81.88%\nEpoch [97/100], Training Loss: 0.0557\nEpoch [97/100] - Validation Loss: 0.5189, Validation Accuracy: 83.28%\nEpoch [98/100], Training Loss: 0.0523\nEpoch [98/100] - Validation Loss: 0.5313, Validation Accuracy: 83.10%\nEpoch [99/100], Training Loss: 0.0500\nEpoch [99/100] - Validation Loss: 0.5138, Validation Accuracy: 82.40%\nEpoch [100/100], Training Loss: 0.0585\nEpoch [100/100] - Validation Loss: 0.5229, Validation Accuracy: 83.45%\n","output_type":"stream"}]},{"cell_type":"code","source":"len(train_losses), len(valid_losses), len(valid_accuracies)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T05:26:48.617152Z","iopub.execute_input":"2023-08-26T05:26:48.618132Z","iopub.status.idle":"2023-08-26T05:26:48.624610Z","shell.execute_reply.started":"2023-08-26T05:26:48.618094Z","shell.execute_reply":"2023-08-26T05:26:48.623614Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"(100, 100, 100)"},"metadata":{}}]},{"cell_type":"code","source":"image_path = '/kaggle/input/wall-classification/good/S-210830_H_X_1_R_98451132009-1.jpg'\nimage = Image.open(image_path)\nimage = data_transforms['train'](image)\nimage = image.unsqueeze(0)  # 배치 차원 추가\n\n# GPU 사용 가능하면 GPU로 전환\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nimage = image.to(device)\nmodel.to(device)\n\n# 예측 수행\nwith torch.no_grad():\n    outputs = model(image)\n\n# 예측 결과 확인\nprobabilities = torch.nn.functional.softmax(outputs[0], dim=0)\npredicted_class = torch.argmax(probabilities).item()\n\n# 클래스 인덱스에 따른 클래스 이름 설정\nclass_names = ['bad', 'good', 'normal']\n\nprint(\"Predicted class:\", class_names[predicted_class])\nprint(\"Class probabilities:\", probabilities)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T05:28:55.093275Z","iopub.execute_input":"2023-08-26T05:28:55.094008Z","iopub.status.idle":"2023-08-26T05:28:55.229830Z","shell.execute_reply.started":"2023-08-26T05:28:55.093969Z","shell.execute_reply":"2023-08-26T05:28:55.228820Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Predicted class: good\nClass probabilities: tensor([7.7979e-02, 9.2154e-01, 4.8391e-04], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}